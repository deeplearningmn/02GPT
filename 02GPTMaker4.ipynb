{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare the data\n",
        "2. Build & train the model\n",
        "3. Cost function, error function, eval\n",
        "4. Inference the model"
      ],
      "metadata": {
        "id": "Jq9kqSex4beW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Qy54PB-teAVi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1 . Prepare the data\n",
        "def prepare_data():\n",
        "  dataset_path = \"/content/dataset_sentiment.xlsx\"\n",
        "  df =  pd.read_excel(dataset_path)\n",
        "  print('total dataset size :',len(df))\n",
        "  headers =  list(df)\n",
        "  print('all dataset header :',headers)\n",
        "\n",
        "  X = df.iloc[:, 0].tolist()\n",
        "  X = np.array(X)\n",
        "\n",
        "  Y = df.iloc[:, 1].tolist()\n",
        "  Y = np.array(Y)\n",
        "  print('prepare_dataset X :',X)\n",
        "  print('prepare_dataset Y :',Y)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y,   test_size=0.2, random_state=1, )\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "\n",
        "#2. 1 Build  the model\n",
        "def build_model():\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  model = Pipeline([\n",
        "              ('vec', vectorizer),\n",
        "              ('clf', GradientBoostingClassifier(verbose=1,n_estimators=300)),\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "#2.2 Train the model\n",
        "def train_model(model,X_train,Y_train):\n",
        "   model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "TldxrYqaHygM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "#3. Cost function, error function, eval\n",
        "def model_eval(model,X_test,X_train,Y_test,Y_train):\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  y_train_pred = model.predict(X_train)\n",
        "\n",
        "  test_acc = accuracy_score(y_test_pred, Y_test)\n",
        "  test_loss = 1 - test_acc\n",
        "  print('test_loss :',test_loss)\n",
        "\n",
        "  train_acc = accuracy_score(y_train_pred, Y_train)\n",
        "  train_loss = 1 - train_acc\n",
        "  print('train_loss :',train_loss)"
      ],
      "metadata": {
        "id": "Hl0A2fV7MsT7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'гүйцээсэн'\n",
        "data = 'онц'\n",
        "\n",
        "#Inference the model\n",
        "def inference_model(model,data):\n",
        "  yhat = model.predict([data])\n",
        "  print('[model] inference yhat[0]:', yhat[0])"
      ],
      "metadata": {
        "id": "mBk3V6vmLvfX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Prepare data\n",
        "X_train, X_test, Y_train, Y_test = prepare_data()\n",
        "\n",
        "#2.1 Build model\n",
        "model = build_model()\n",
        "\n",
        "#2.2 Train model\n",
        "train_model(model,X_train,Y_train)\n",
        "\n",
        "#3. Eval the model\n",
        "model_eval(model,X_test,X_train,Y_test,Y_train)\n",
        "\n",
        "#4. inference model\n",
        "inference_model(model,'онц')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKIYrHk5Azwf",
        "outputId": "1429b819-a978-4e53-e87a-d59359c81452"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total dataset size : 132\n",
            "all dataset header : ['Words', 'Label']\n",
            "prepare_dataset X : ['татгалзах' 'хаягдсан' 'хулгайлсан' 'хүний \\u200b\\u200bхулгай'\n",
            " 'хулгайлах' 'дургүйцэх\\xa0' 'Хөгшрөлт' 'чадвартай' 'байхгүй' 'зөвтгөх'\n",
            " 'шингээгдсэн' 'буруугаар хэрэглэх' 'доромжлолт' 'хүлээн авсан'\n",
            " 'хүлээн авах' 'осол' 'санамсаргүй байдлаар' 'хийж гүйцэтгэх' 'гүйцээсэн'\n",
            " 'ял' 'онцлох хүнс' 'буруушаах' 'гэмтэн' 'гоё' 'онц' 'өвдсөн' 'өвчин'\n",
            " 'үртэй' 'хүнд өвдөх' 'зөвтгөх' 'олсон' 'урьдчилан авах' 'идэвхтэй'\n",
            " 'нийцсэн' 'гайхах' 'амьдаар биш' 'уурладаг' 'гунигтай хүмүүс' 'багтаах'\n",
            " 'үзсэн' 'зөвшөөрсөн' 'тэтгэвэр' 'үрчилж авах' 'гайхмаар' 'шүтэх'\n",
            " 'тушаал сонссон' 'шуугиантай' 'дэвшилттэй' 'давуу тал' 'сурталчилгаа'\n",
            " 'адал явдал' 'сэтгэл хөндсөн' 'дур хүсэл' 'энхрий' 'хүндлэх' 'суув'\n",
            " 'айсан' 'хүндрүүлэх' 'хүндэрсэн' 'түрэмгийлэл' 'түрэмгий' 'нээлттэй'\n",
            " 'зовж шаналах' 'дээшгээ орсон' 'зовлон зүдүүр' 'зовж шаналах' 'зөвшөөрөх'\n",
            " 'нийцтэй' 'тохирсон' 'тохиролцоо' 'сул хөгжил' 'түгшүүр' 'сэргээх'\n",
            " 'байгууллага' 'соргог байх' 'хөндиирэх явдал' 'амьд' 'харшилтай'\n",
            " 'ганцаараа' 'гайхуулах' 'гайхав' 'гайхалтай' 'нэр хүндэд дуртай' 'цэнгэх'\n",
            " 'зүгаа цэнгэл' 'сургамж' 'уур хилэн' 'аялал' 'ууртай' 'шаналав'\n",
            " 'дайсагнал' 'цухалдуулах' 'харамсал' 'ядаргаатай' 'зовнил' 'санаа зөвсон'\n",
            " 'өршөөл гуйх' 'ойлгөлоо' 'Бурхан' 'өршөөл гуйх' 'ойлгөлоо'\n",
            " 'уучилсан зовнил' 'хүндэтгэх' 'аймаар' 'тайтгаруулах' 'сануулсан'\n",
            " 'алга таших' 'алга ташсан' 'алга таших' 'алга ташилт' 'өндөр үнэлэх'\n",
            " 'хангасан' 'үнэлдэг' 'талархал' 'түргэн сэтгэдэг' 'сайшаал' 'сайжруулсан'\n",
            " 'зөвшөөрсөн' 'баривчлага' 'харгаламж' 'дээрэлхүү' 'ичмээр' 'ичиж зовсон'\n",
            " 'аллага' 'ухаан алдах' 'түргэн' 'новш' 'гайхсан' 'гайхуулах' 'гайхмаар'\n",
            " 'Драйс' 'сэтгэл татах']\n",
            "prepare_dataset Y : ['negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'positive' 'neutral' 'positive' 'neutral' 'negative'\n",
            " 'negative' 'neutral' 'neutral' 'negative' 'neutral' 'positive' 'positive'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
            " 'negative' 'negative' 'neutral' 'negative' 'positive' 'positive'\n",
            " 'positive' 'neutral' 'neutral' 'neutral' 'neutral' 'negative' 'negative'\n",
            " 'neutral' 'neutral' 'positive' 'neutral' 'neutral' 'positive' 'positive'\n",
            " 'positive' 'positive' 'neutral' 'positive' 'neutral' 'neutral' 'neutral'\n",
            " 'positive' 'positive' 'positive' 'neutral' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'neutral' 'negative' 'negative'\n",
            " 'negative' 'negative' 'positive' 'positive' 'neutral' 'neutral' 'neutral'\n",
            " 'negative' 'positive' 'neutral' 'neutral' 'negative' 'neutral' 'negative'\n",
            " 'neutral' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
            " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'negative' 'negative'\n",
            " 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'neutral' 'positive'\n",
            " 'negative' 'positive' 'neutral' 'positive' 'positive' 'positive'\n",
            " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
            " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
            " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
            " 'positive' 'positive' 'positive' 'neutral' 'positive']\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.0678            1.70s\n",
            "         2           1.0485            1.71s\n",
            "         3           1.0324            1.62s\n",
            "         4           1.0184            1.58s\n",
            "         5           1.0060            1.55s\n",
            "         6           0.9935            1.53s\n",
            "         7           0.9812            1.64s\n",
            "         8           0.9691            1.83s\n",
            "         9           0.9573            1.78s\n",
            "        10           0.9455            1.82s\n",
            "        20           0.8412            1.49s\n",
            "        30           0.7545            1.33s\n",
            "        40           0.6812            1.29s\n",
            "        50           0.6181            1.20s\n",
            "        60           0.5631            1.13s\n",
            "        70           0.5144            1.08s\n",
            "        80           0.4713            1.03s\n",
            "        90           0.4328            1.00s\n",
            "       100           0.3982            0.96s\n",
            "       200           0.1853            0.47s\n",
            "       300           0.0918            0.00s\n",
            "test_loss : 0.5555555555555556\n",
            "train_loss : 0.0\n",
            "[model] inference yhat[0]: positive\n"
          ]
        }
      ]
    }
  ]
}